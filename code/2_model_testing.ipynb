{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Modelling: Classifying Subreddits Based On Text\n",
    "\n",
    "In this notebook, I compare test/train scores on my data using the following four models. For each model, I used CountVectorizer and TfidfVectorizer a range of hyperparamters set with Pipeline for a total of 8 models. I toggled features out until I found optimized settings. \n",
    "\n",
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbors\n",
    "3. Naive Bayes: Bernoulli\n",
    "4. Naive Bayes: Multinomial\n",
    "\n",
    "Following the 8 models, I compare their scores to see which models I will use for the rest of this project. My X variable is the text scraped and cleaned in my first notebook (both submissions and comments), and my y variable is the subreddit whence the text came. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import modelling libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Cleaned Data & Prepare Variables For Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "west_house = pd.read_csv('../data/west_house.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nulls just to be safe\n",
    "west_house.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets X variable as text column and sets y variable as subreddit column\n",
    "# Prepares train/test split\n",
    "X = west_house['text']\n",
    "y = west_house['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.50069\n",
       "0    0.49931\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets a baseline accuracy score\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipe & Grid CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.7950133868808568\n",
      "Test:  0.7772202709483191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec__max_df': 0.25,\n",
       " 'vec__max_features': 250,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets pipeline to transformer and estimator\n",
    "pipe = Pipeline([('vec', CountVectorizer()),\n",
    "                 ('model', LogisticRegression())])\n",
    "\n",
    "# Sets pipeline paramters to toggle hyperparamter settings on/off\n",
    "pipe_params = {\n",
    "    'vec__max_features': [\n",
    "                        #50, \n",
    "                        #100,\n",
    "                        250\n",
    "                        #500,\n",
    "                        #600,\n",
    "                        #1000, \n",
    "                        #5000\n",
    "                        ],\n",
    "    'vec__min_df': [\n",
    "                   #1,\n",
    "                   2, \n",
    "                   3, \n",
    "                   #5,\n",
    "                   #10 \n",
    "                   ],\n",
    "    'vec__max_df': [\n",
    "                   #.1,\n",
    "                   .25, \n",
    "                   .33, \n",
    "                   #.5, \n",
    "                   #.9\n",
    "                    ],\n",
    "    'vec__ngram_range': [\n",
    "                        (1, 1), \n",
    "                        (1, 2),\n",
    "                        #(1, 3),\n",
    "                        #(1, 4)\n",
    "                        ]\n",
    "                        }\n",
    "\n",
    "# Passes transformer/estimator Pipeline into GridSearch \n",
    "grid = GridSearchCV(pipe, \n",
    "                       pipe_params,\n",
    "                       cv=5)\n",
    "\n",
    "# Fits GridSearch model to X_train and y_train\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Assigns best estimator to variable and scores both train and test datasets\n",
    "mod = grid.best_estimator_\n",
    "print('Train: ', mod.score(X_train, y_train))\n",
    "print('Test: ', mod.score(X_test, y_test))\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipe & Grid TfidfVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.7961847389558233\n",
      "Test:  0.772704465629704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec__max_df': 0.25,\n",
       " 'vec__max_features': 250,\n",
       " 'vec__min_df': 2,\n",
       " 'vec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets pipeline to transformer and estimator\n",
    "pipe = Pipeline([('vec', TfidfVectorizer()),\n",
    "                 ('model', LogisticRegression())])\n",
    "\n",
    "# Sets pipeline paramters to toggle hyperparamter settings on/off\n",
    "pipe_params = {\n",
    "    'vec__max_features': [\n",
    "                        #50, \n",
    "                        #100,\n",
    "                        250\n",
    "                        #500,\n",
    "                        #600,\n",
    "                        #1000, \n",
    "                        #5000\n",
    "                        ],\n",
    "    'vec__min_df': [\n",
    "                   #1,\n",
    "                   2, \n",
    "                   3, \n",
    "                   #5,\n",
    "                   #10 \n",
    "                   ],\n",
    "    'vec__max_df': [\n",
    "                   #.1,\n",
    "                   .25, \n",
    "                   .33, \n",
    "                   #.5, \n",
    "                   #.9\n",
    "                    ],\n",
    "    'vec__ngram_range': [\n",
    "                        (1, 1), \n",
    "                        (1, 2),\n",
    "                        #(1, 3),\n",
    "                        #(1, 4)\n",
    "                        ]\n",
    "                        }\n",
    "\n",
    "# Passes transformer/estimator Pipeline into GridSearch \n",
    "grid = GridSearchCV(pipe, \n",
    "                       pipe_params,\n",
    "                       cv=5)\n",
    "\n",
    "# Fits GridSearch model to X_train and y_train\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Assigns best estimator to variable and scores both train and test datasets\n",
    "mod = grid.best_estimator_\n",
    "print('Train: ', mod.score(X_train, y_train))\n",
    "print('Test: ', mod.score(X_test, y_test))\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipe & Grid CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.7873159303882196\n",
      "Test:  0.6909182137481185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec__max_df': 0.33,\n",
       " 'vec__max_features': 500,\n",
       " 'vec__min_df': 3,\n",
       " 'vec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets pipeline to transformer and estimator\n",
    "pipe = Pipeline([('vec', CountVectorizer()),\n",
    "                 ('model', KNeighborsClassifier())])\n",
    "\n",
    "# Sets pipeline paramters to toggle hyperparamter settings on/off\n",
    "pipe_params = {\n",
    "    'vec__max_features': [\n",
    "                        #50, \n",
    "                        #100, \n",
    "                        500,\n",
    "                        #600,\n",
    "                        1000, \n",
    "                        #5000\n",
    "                        ],\n",
    "    'vec__min_df': [\n",
    "                   1, \n",
    "                   3, \n",
    "                   5,\n",
    "                   #10 \n",
    "                   ],\n",
    "    'vec__max_df': [\n",
    "                   .1, \n",
    "                   .33, \n",
    "                   .5, \n",
    "                   #.9\n",
    "                    ],\n",
    "    'vec__ngram_range': [\n",
    "                        (1, 1), \n",
    "                        (1, 2),\n",
    "                        #(1, 3),\n",
    "                        #(1, 4)\n",
    "                        ]\n",
    "                        }\n",
    "\n",
    "# Passes transformer/estimator Pipeline into GridSearch \n",
    "grid = GridSearchCV(pipe, \n",
    "                       pipe_params,\n",
    "                       cv=5)\n",
    "\n",
    "# Fits GridSearch model to X_train and y_train\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Assigns best estimator to variable and scores both train and test datasets\n",
    "mod = grid.best_estimator_\n",
    "print('Train: ', mod.score(X_train, y_train))\n",
    "print('Test: ', mod.score(X_test, y_test))\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipe & Grid TfidfVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.7655622489959839\n",
      "Test:  0.6292022077270446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec__max_df': 0.33,\n",
       " 'vec__max_features': 500,\n",
       " 'vec__min_df': 3,\n",
       " 'vec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets pipeline to transformer and estimator\n",
    "pipe = Pipeline([('vec', TfidfVectorizer()),\n",
    "                 ('model', KNeighborsClassifier())])\n",
    "\n",
    "# Sets pipeline paramters to toggle hyperparamter settings on/off\n",
    "pipe_params = {\n",
    "    'vec__max_features': [\n",
    "                        #50, \n",
    "                        #100, \n",
    "                        500,\n",
    "                        #600,\n",
    "                        1000, \n",
    "                        #5000\n",
    "                        ],\n",
    "    'vec__min_df': [\n",
    "                   1, \n",
    "                   3, \n",
    "                   5,\n",
    "                   #10 \n",
    "                   ],\n",
    "    'vec__max_df': [\n",
    "                   #.1, \n",
    "                   .33, \n",
    "                   .5, \n",
    "                   #.9\n",
    "                    ],\n",
    "    'vec__ngram_range': [\n",
    "                        (1, 1), \n",
    "                        (1, 2),\n",
    "                        #(1, 3),\n",
    "                        #(1, 4)\n",
    "                        ]\n",
    "                        }\n",
    "\n",
    "# Passes transformer/estimator Pipeline into GridSearch \n",
    "grid = GridSearchCV(pipe, \n",
    "                       pipe_params,\n",
    "                       cv=5)\n",
    "\n",
    "# Fits GridSearch model to X_train and y_train\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Assigns best estimator to variable and scores both train and test datasets\n",
    "mod = grid.best_estimator_\n",
    "print('Train: ', mod.score(X_train, y_train))\n",
    "print('Test: ', mod.score(X_test, y_test))\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipe & Grid CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8122489959839357\n",
      "Test:  0.8023080782739589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec__max_df': 0.33,\n",
       " 'vec__max_features': 600,\n",
       " 'vec__min_df': 10,\n",
       " 'vec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets pipeline to transformer and estimator\n",
    "pipe = Pipeline([('vec', CountVectorizer()),\n",
    "                 ('model', MultinomialNB())])\n",
    "\n",
    "# Sets pipeline paramters to toggle hyperparamter settings on/off\n",
    "pipe_params = {\n",
    "    'vec__max_features': [\n",
    "                        #50, \n",
    "                        #100, \n",
    "                        #500,\n",
    "                        600,\n",
    "                        #1000, \n",
    "                        #5000\n",
    "                        ],\n",
    "    'vec__min_df': [\n",
    "                   #1, \n",
    "                   #3, \n",
    "                   #5,\n",
    "                   10 \n",
    "                   ],\n",
    "    'vec__max_df': [\n",
    "                   .1, \n",
    "                   .33, \n",
    "                   #.5, \n",
    "                   #.9\n",
    "                    ],\n",
    "    'vec__ngram_range': [\n",
    "                        (1, 1), \n",
    "                        (1, 2),\n",
    "                        #(1, 3),\n",
    "                        #(1, 4)\n",
    "                        ]\n",
    "                        }\n",
    "\n",
    "# Passes transformer/estimator Pipeline into GridSearch \n",
    "grid = GridSearchCV(pipe, \n",
    "                       pipe_params,\n",
    "                       cv=5)\n",
    "\n",
    "# Fits GridSearch model to X_train and y_train\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Assigns best estimator to variable and scores both train and test datasets\n",
    "mod = grid.best_estimator_\n",
    "print('Train: ', mod.score(X_train, y_train))\n",
    "print('Test: ', mod.score(X_test, y_test))\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipe & Grid TfidfVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8274765729585006\n",
      "Test:  0.787255393878575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec__max_df': 0.33,\n",
       " 'vec__max_features': 600,\n",
       " 'vec__min_df': 10,\n",
       " 'vec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets pipeline to transformer and estimator\n",
    "pipe = Pipeline([('vec', TfidfVectorizer()),\n",
    "                 ('model', MultinomialNB())])\n",
    "\n",
    "# Sets pipeline paramters to toggle hyperparamter settings on/off\n",
    "pipe_params = {\n",
    "    'vec__max_features': [\n",
    "                        #50, \n",
    "                        #100, \n",
    "                        #500,\n",
    "                        600,\n",
    "                        #1000, \n",
    "                        #5000\n",
    "                        ],\n",
    "    'vec__min_df': [\n",
    "                   #1, \n",
    "                   #3, \n",
    "                   #5,\n",
    "                   10 \n",
    "                   ],\n",
    "    'vec__max_df': [\n",
    "                   #.1, \n",
    "                   .33, \n",
    "                   #.5, \n",
    "                   #.9\n",
    "                    ],\n",
    "    'vec__ngram_range': [\n",
    "                        (1, 1), \n",
    "                        (1, 2),\n",
    "                        #(1, 3),\n",
    "                        #(1, 4)\n",
    "                        ]\n",
    "                        }\n",
    "\n",
    "# Passes transformer/estimator Pipeline into GridSearch \n",
    "grid = GridSearchCV(pipe, \n",
    "                       pipe_params,\n",
    "                       cv=5)\n",
    "\n",
    "# Fits GridSearch model to X_train and y_train\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Assigns best estimator to variable and scores both train and test datasets\n",
    "mod = grid.best_estimator_\n",
    "print('Train: ', mod.score(X_train, y_train))\n",
    "print('Test: ', mod.score(X_test, y_test))\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipe & Grid CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.7901606425702812\n",
      "Test:  0.7757150025087808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec__max_df': 0.33,\n",
       " 'vec__max_features': 600,\n",
       " 'vec__min_df': 5,\n",
       " 'vec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets pipeline to transformer and estimator\n",
    "pipe = Pipeline([('vec', CountVectorizer()),\n",
    "                 ('model', BernoulliNB())])\n",
    "\n",
    "# Sets pipeline paramters to toggle hyperparamter settings on/off\n",
    "pipe_params = {\n",
    "    'vec__max_features': [\n",
    "                        #50, \n",
    "                        #100, \n",
    "                        #500,\n",
    "                        600,\n",
    "                        #1000, \n",
    "                        #5000\n",
    "                        ],\n",
    "    'vec__min_df': [\n",
    "                   #1, \n",
    "                   #3, \n",
    "                   5,\n",
    "                   10 \n",
    "                   ],\n",
    "    'vec__max_df': [\n",
    "                   .1, \n",
    "                   .33, \n",
    "                   #.5, \n",
    "                   #.9\n",
    "                    ],\n",
    "    'vec__ngram_range': [\n",
    "                        (1, 1), \n",
    "                        (1, 2),\n",
    "                        #(1, 3),\n",
    "                        #(1, 4)\n",
    "                        ]\n",
    "                        }\n",
    "\n",
    "# Passes transformer/estimator Pipeline into GridSearch \n",
    "grid = GridSearchCV(pipe, \n",
    "                       pipe_params,\n",
    "                       cv=5)\n",
    "\n",
    "# Fits GridSearch model to X_train and y_train\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Assigns best estimator to variable and scores both train and test datasets\n",
    "mod = grid.best_estimator_\n",
    "print('Train: ', mod.score(X_train, y_train))\n",
    "print('Test: ', mod.score(X_test, y_test))\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipe & Grid TfidfVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.7901606425702812\n",
      "Test:  0.7757150025087808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'vec__max_df': 0.33,\n",
       " 'vec__max_features': 600,\n",
       " 'vec__min_df': 5,\n",
       " 'vec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets pipeline to transformer and estimator\n",
    "pipe = Pipeline([('vec', TfidfVectorizer()),\n",
    "                 ('model', BernoulliNB())])\n",
    "\n",
    "# Sets pipeline paramters to toggle hyperparamter settings on/off\n",
    "pipe_params = {\n",
    "    'vec__max_features': [\n",
    "                        #50, \n",
    "                        #100, \n",
    "                        #500,\n",
    "                        600,\n",
    "                        #1000, \n",
    "                        #5000\n",
    "                        ],\n",
    "    'vec__min_df': [\n",
    "                   #1, \n",
    "                   #3, \n",
    "                   5,\n",
    "                   10 \n",
    "                   ],\n",
    "    'vec__max_df': [\n",
    "                   #.1, \n",
    "                   .33, \n",
    "                   #.5, \n",
    "                   #.9\n",
    "                    ],\n",
    "    'vec__ngram_range': [\n",
    "                        (1, 1), \n",
    "                        (1, 2),\n",
    "                        #(1, 3),\n",
    "                        #(1, 4)\n",
    "                        ]\n",
    "                        }\n",
    "\n",
    "# Passes transformer/estimator Pipeline into GridSearch \n",
    "grid = GridSearchCV(pipe, \n",
    "                       pipe_params,\n",
    "                       cv=5)\n",
    "\n",
    "# Fits GridSearch model to X_train and y_train\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Assigns best estimator to variable and scores both train and test datasets\n",
    "mod = grid.best_estimator_\n",
    "print('Train: ', mod.score(X_train, y_train))\n",
    "print('Test: ', mod.score(X_test, y_test))\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis\n",
    "\n",
    "In the fine-tuning process above, I quickly noticed that KNN was performing much more poory than the others, and I abandoned it without spending too much time adjusting the hyperparamters. The variance was high AND the scores were low, and mitigating variance would almost certainly drop the higher score down even more. \n",
    "\n",
    "Of the two Naive Bayes models tried, Bernoulli performed slightly worse than Multinomial. I actually suspected Bernoulli to perform much worse, since Bernoulli is supposed to be used with binary X variables and neither CountVectorizer nor TfidfVectorizer convert data into stricty 1s and 0s. I assume Bernoulli did so well because though CVec and TVec don't only use 1s and 0s, the data is mostly composed of 1s and 0s.\n",
    "\n",
    "The remaining four estimator/transformer combinations above produced very similar optimal scores after several rounds of hyperparamter tweaking. Mulitnomial Naive Bayes with CountVectorizer had both train and test scores over 80, so that will be my Naive Bayes model. Though Logistic Regression performed better with CountVectorizer than with TfidfVectorizer, the difference is marginal, and I'd like to use two completely different models (with different transformers) so that I can approach my data in two completely different ways. I will use these two models for the rest of the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
